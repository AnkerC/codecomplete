# 工具使用
## 性能相关
fio
```






eg:

fio -filename=/tmp/test_randread -direct=1 -iodepth 1 -thread -rw=randread -ioengine=libaio -bs=16k -size=2G -numjobs=10 -runtime=60 -group_reporting -name=mytest

说明：
filename=/dev/sdb1       测试文件名称，通常选择需要测试的盘的data目录。
direct=1                 测试过程绕过机器自带的buffer。使测试结果更真实。
rw=randwrite             测试随机写的I/O
rw=randrw                测试随机写和读的I/O
bs=16k                   单次io的块文件大小为16k
bsrange=512-2048         同上，提定数据块的大小范围
size=5g    本次的测试文件大小为5g，以每次4k的io进行测试。
numjobs=30               本次的测试线程为30.
runtime=1000             测试时间为1000秒，如果不写则一直将5g文件分4k每次写完为止。
ioengine=psync           io引擎使用pync方式
rwmixwrite=30            在混合读写的模式下，写占30%
group_reporting          关于显示结果的，汇总每个进程的信息。

此外
lockmem=1g               只使用1g内存进行测试。
zero_buffers             用0初始化系统buffer。
nrfiles=8                每个进程生成文件的数量。

输出参数解释：



eg:
[root@KingStack-FIO ~]# fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randwrite -size=1000G -filename=/dev/vdb -name="KingStack EBS 4K randwrite test" -iodepth=1 -runtime=60 
简单介绍一下FIO的参数： 
ioengine: 负载引擎，一般使用libaio，发起异步IO请求。 
bs: 单次IO的块文件大小为4K。 
direct: 绕过操作系统Cache。因为我们测试的是磁盘，而不是操作系统的Cache，所以设置为1，使测试结果更真实。 
rw: randwrite 测试随机写的I/0。 
size: 寻址空间，一般设置为磁盘的大小。 
filename: 测试对象。 
iodepth: 队列深度，只有使用libaio时才有意义。这是一个可以影响IOPS的参数。 
runtime: 测试时长



```

iostat
关于iostat解释
http://linuxperf.com/?p=156

iostat -x 1执行的结果
```

03/29/2018 08:33:19 PM
avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           4.60    0.00    3.58    0.00    0.00   91.82

Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
fd0               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00
sda               0.00     5.00    0.00   15.00     0.00   108.00    14.40     0.00    0.27    0.00    0.27   0.27   0.40
sdb               0.00    55.00    0.00   19.00     0.00 11040.00  1162.11     0.42   23.58    0.00   23.58   5.89  11.20
sdd               0.00    53.00    0.00   15.00     0.00  8212.00  1094.93     0.09    6.13    0.00    6.13   3.47   5.20
sde               0.00    52.00    0.00   16.00     0.00  8212.00  1026.50     0.25   15.75    0.00   15.75   3.75   6.00
sdc               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00

参数解释：
tps：每秒I/O次数=[(Δrd_ios+Δwr_ios)/Δt]
r/s：每秒读操作的次数=[Δrd_ios/Δt]
w/s：每秒写操作的次数=[Δwr_ios/Δt]
rkB/s：每秒读取的千字节数=[Δrd_sectors/Δt]*[512/1024]
wkB/s：每秒写入的千字节数=[Δwr_sectors/Δt]*[512/1024]
rrqm/s：每秒合并读操作的次数=[Δrd_merges/Δt]
wrqm/s：每秒合并写操作的次数=[Δwr_merges/Δt]
avgrq-sz：每个I/O的平均扇区数=[Δrd_sectors+Δwr_sectors]/[Δrd_ios+Δwr_ios]
avgqu-sz：平均未完成的I/O请求数量=[Δtime_in_queue/Δt]
（手册上说是队列里的平均I/O请求数量，更恰当的理解应该是平均未完成的I/O请求数量。）
await：每个I/O平均所需的时间=[Δrd_ticks+Δwr_ticks]/[Δrd_ios+Δwr_ios] 单位应该是毫秒ms
（不仅包括硬盘设备处理I/O的时间，还包括了在kernel队列中等待的时间。）
r_await：每个读操作平均所需的时间=[Δrd_ticks/Δrd_ios] 单位是
不仅包括硬盘设备读操作的时间，还包括了在kernel队列中等待的时间。
w_await：每个写操作平均所需的时间=[Δwr_ticks/Δwr_ios]
不仅包括硬盘设备写操作的时间，还包括了在kernel队列中等待的时间。
%util：该硬盘设备的繁忙比率=[Δio_ticks/Δt]
表示该设备有I/O（即非空闲）的时间比率，不考虑I/O有多少，只考虑有没有。
svctm：已被废弃的指标，没什么意义，svctm=[util/tput]



%util与硬盘设备饱和度
%util表示该设备有I/O（即非空闲）的时间比率，不考虑I/O有多少，只考虑有没有。由于现代硬盘设备都有并行处理多个I/O请求的能力，所以%util即使达到100%也不意味着设备饱和了。举个简化的例子：某硬盘处理单个I/O需要0.1秒，有能力同时处理10个I/O请求，那么当10个I/O请求依次顺序提交的时候，需要1秒才能全部完成，在1秒的采样周期里%util达到100%；而如果10个I/O请求一次性提交的话，0.1秒就全部完成，在1秒的采样周期里%util只有10%。可见，即使%util高达100%，硬盘也仍然有可能还有余力处理更多的I/O请求，即没有达到饱和状态。那么iostat(1)有没有哪个指标可以衡量硬盘设备的饱和程度呢？很遗憾，没有

IO处理：寻道+
```


vmstat
vmstat [option] interval
```
root@aStor-0790:~# vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 4  0      0 22834888 294956 1181308    0    0  1294  3550  170  168  5  4 86  5  0
 1  0      0 22863128 294956 1181384    0    0     0  1092 16225 37479 12 12 75  2  0
 2  0      0 22829056 294956 1181344    0    0     0   224 18085 38475  6  9 85  1  0
 3  0      0 22862328 294956 1181392    0    0     0   484 19214 40007  9 18 73  0  0
 1  1      0 22859724 294956 1181500    0    0     0  1424 14700 37022 11  9 78  2  0
 3  0      0 22853192 294964 1181536    0    0     0  1068 11680 32086  5  3 91  1  0
 0  0      0 22858400 294964 1181624    0    0     0   508 10562 31123  9  2 88  1  0
```
procs进程
r: 运行队列中进程数量，这个值也可以判断是否需要增加CPU。（长期大于1）
b: 等待IO的进程数量

memory进程
swpd: 使用虚拟内存大小，如果swpd的值不为0，但是SI，SO的值长期为0，这种情况不会影响系统性能。
free: 空闲物理内存大小。
buff: 用作缓冲的内存大小。
cache: 用作缓存的内存大小，如果cache的值大的时候，说明cache处的文件数多，如果频繁访问到的文件都能被cache处，那么磁盘的读IO bi会非常小
Swap

si: 每秒从交换区写到内存的大小，由磁盘调入内存。
so: 每秒写入交换区的内存大小，由内存调入磁盘

IO


bi: 每秒读取的块数
bo: 每秒写入的块数

system（系统）

in: 每秒中断数，包括时钟中断。
cs: 每秒上下文切换数

CPU（以百分比表示）

us: 用户进程执行时间百分比(user time)
us的值比较高时，说明用户进程消耗的CPU时间多，但是如果长期超50%的使用，那么我们就该考虑优化程序算法或者进行加速。

sy: 内核系统进程执行时间百分比(system time)
sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因。

wa: IO等待时间百分比
wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。

id: 空闲时间百分比



```
root@aStor-0790:~# vmstat -p /dev/sdj1 1
sdj1          reads   read sectors  writes    requested writes
                 373      15940        226      14346
                 373      15940        226      14346

```
-p 加分区显示分区的读写



### mpstat
查看进程占用CPU情况
mpstat -A  == -u -I ALL -P ALL
-u: 显示CPU使用情况
-P ALL：显示每个逻辑核的使用
-I ALL：显示

atop
参数解释见下面链接
https://www.cnblogs.com/chenmh/p/5481700.html

### iotop


dstat



sar



top

ps




perf


lttng

strace


ftrace

###blktrace

    http://bean-li.github.io/blktrace-to-report/





### pidstat 





tcpdump

    tcpdump -i eth1

    tcpdump host 210.27.48.1
截获主机210.27.48.1 和主机210.27.48.2 或210.27.48.3的通信
    tcpdump host 210.27.48.1 and \ (210.27.48.2 or 210.27.48.3 \)



lsof


fuser

将正在使用/var/lib/ceph/osd/ceph-0的进程杀死，来让下一步umount /var/lib/ceph/osd/ceph-0 执行成功
fuser -k -m /var/lib/ceph/osd/ceph-0




rados bench

rados -p <pool_name>  bench <second> <write/seq/rand> [一些选项]

```
root@aStor-2388:~# rados -p replica_pool  bench 30 write 
hints = 1
Maintaining 16 concurrent writes of 4194304 bytes to objects of size 4194304 for up to 30 seconds or 0 objects
Object prefix: benchmark_data_aStor-2388_20688
  sec Cur ops   started  finished  avg MB/s  cur MB/s last lat(s)  avg lat(s)
    0       0         0         0         0         0           -           0
    1      16       105        89   350.662       356    0.218068    0.162991
    2      16       195       179   355.265       360      0.2062     0.17144
    ...
Total time run:         30.047131
Total writes made:      2051
Write size:             4194304
Object size:            4194304
Bandwidth (MB/sec):     273.038
Stddev Bandwidth:       59.15
Max bandwidth (MB/sec): 384
Min bandwidth (MB/sec): 188
Average IOPS:           68
Stddev IOPS:            14
Max IOPS:               96
Min IOPS:               47
Average Latency(s):     0.234344
Stddev Latency(s):      0.104834
Max latency(s):         0.784426
Min latency(s):         0.0387572
Cleaning up (deleting benchmark objects)
Removed 2051 objects
Clean up completed and total clean up time :1.714289


```



rbd bench/bench-write








## 磁盘相关命令
parted

fdisk

lsscsi

mkfs

fsck

mount

umount


smartctl

hdparm

sdparm







## IO分析

如何看客户端的IO大小
ceph端使用perf counter看，linux端使用perf看

开始统计：perf record -e block:block_rq_issue -a
查看结果：perf script
用主次设备号过滤一下结果
perf script | grep 8,0



directIO
    绕过内核的cache,测试的结果更可靠和真是
    参照下面这个图
    https://www.cnblogs.com/youngerchina/p/5624462.html

IO深度：
    io深度对IOPS的影响：
    http://www.ksyun.com/blog/dui-lie-shen-du-dui-ci-pan-iopsde-ying-xiang/
    结论：
        增加队列深度，可以看到IOPS不会随着队列深度的增加而一直增加，达到一定值后会有所下降。 
        增加队列深度，可以测试出磁盘的峰值


IO调度算法
查看linux IO调度算法
```
root@aStor-9463:~# cat /sys/block/sdb/queue/scheduler
noop [deadline] cfq 
```



查看linux 块设备相关信息
    /sys/block/sdX/

/proc/diskstats内容


### perf

ceph daemon /var/run/ceph/ceph-osd.0.asok perf dump









